{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf2fca92",
   "metadata": {},
   "source": [
    "# 00. PyTorch Fundamentals\n",
    "\n",
    "First, we import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6a7ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac07b00",
   "metadata": {},
   "source": [
    "## Introduction to Tensors\n",
    "\n",
    "### Creating tensors\n",
    "\n",
    "PyTorch tensors are created using `torch.Tensor()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd0ef1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scalar\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c72b353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "002ea034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get tensor back as Python int\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07060c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28455133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "015a8750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8438b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix \n",
    "MATRIX = torch.tensor([[7,8], [9,10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f90981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80076fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950e1466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4bb52916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [6, 7, 8]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor \n",
    "TENSOR = torch.tensor([[[1,2,3], \n",
    "                        [4,5,6], \n",
    "                        [6,7,8]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50e61b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1874380d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7f64cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [6, 7, 8]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f287430",
   "metadata": {},
   "source": [
    "Scalars and vectors are usually named by lower case variables and matrices and tensors are usually named by an upper case variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17a1437",
   "metadata": {},
   "source": [
    "### Random Tensors\n",
    "\n",
    "Why random tensors? Random tensors are important because the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa38589f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8605, 0.5427, 0.6301, 0.9966],\n",
       "        [0.4097, 0.1481, 0.7933, 0.9278],\n",
       "        [0.9383, 0.8417, 0.5006, 0.9078]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of shape (3,4). Returns a tensor filled with random numbers from a uniform distribution on the interval \n",
    "\n",
    "random_tensor = torch.rand(3,4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b9437f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor with similar shape to an image tensor\n",
    "\n",
    "random_image_size_tensor = torch.rand(size=(224,224,3)) # height, width, colour channel\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6872052d",
   "metadata": {},
   "source": [
    "### Zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4706b3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3,4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7406b267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3,4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34f2941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default data type in PyTorch is torch.float32\n",
    "ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e9c23e",
   "metadata": {},
   "source": [
    "### Create a range of tensors and tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e973db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/ltq9r3wj777dpt6fbrs3clz00000gp/T/ipykernel_20045/3858421243.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  torch.range(0,10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use torch.range() -> deprecated\n",
    "torch.range(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "92a9d530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 5, 7, 9])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Better to use torch.arange()\n",
    "one_to_ten = torch.arange(start=1,end=11,step=2)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "46c85ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tensors like -> takes the shape of the input\n",
    "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ec4b40",
   "metadata": {},
   "source": [
    "### Tensor datatypes\n",
    "\n",
    "**Note:** Tensor datastypes is one of the 3 big errors you'll run into with PyTorch & deep learning:\n",
    "1. Tensors not right datatype\n",
    "2. Tensors not right shape\n",
    "3. Tensors not on the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2926ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float32 tensor -> Default is float32\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0], \n",
    "                               dtype=None,              # datatype of float tensors\n",
    "                               device=None,             # What device is your tensor on. By default cpu, operations between two tensors that don't live on the same device yields an error\n",
    "                               requires_grad=False      # Whether or not to track gradients with this tensors operations\n",
    "                               )\n",
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cf0f4528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float16 tensor \n",
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "068158af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.], dtype=torch.float16)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor * float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8bab0892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.], dtype=torch.float16)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3,6,9], dtype=torch.int64)\n",
    "int_32_tensor * float_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6841bdb5",
   "metadata": {},
   "source": [
    "Pretty robust regarding multiplications of tensors of different datatypes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eba87af",
   "metadata": {},
   "source": [
    "### Getting information from tensors (tensor attributes)\n",
    "\n",
    "1. Datatype - use `tensor.dtype`\n",
    "2. Shape - use `tensor.shape`\n",
    "3. Device - use `tensor.device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "25f182f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.Size([3, 4]), device(type='cpu'))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor = torch.rand(3,4)\n",
    "some_tensor.dtype, some_tensor.shape, some_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf329b2",
   "metadata": {},
   "source": [
    "### Manipulating Tensors (tensor operations)\n",
    "\n",
    "Tensor operations include:\n",
    "* Addition\n",
    "* Subtraction\n",
    "* Multiplication\n",
    "* Division\n",
    "* Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "45de1d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([101, 102, 103])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Addition\n",
    "tensor = torch.tensor([1,2,3])\n",
    "tensor + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "45de251d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtraction \n",
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "12aa1bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplication\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4b10656c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.2000, 0.3000])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Division\n",
    "tensor / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f9cedd14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try out PyTorch in-built functions\n",
    "torch.mul(tensor,10)        # multiplication\n",
    "torch.add(tensor, 10)       # addition\n",
    "torch.subtract(tensor, 10)  # subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6e3e645f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Elementwise matrix multiplication\n",
    "print(tensor, \"*\", tensor)\n",
    "print(f\"Equals: {tensor*tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3854c3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "torch.matmul(tensor,tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a49dec4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication 2\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8ab228",
   "metadata": {},
   "source": [
    "### One of the most common errors in deep learning: shape errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "c978c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapes for matrix multiplication\n",
    "tensor_A = torch.tensor([[1,2],\n",
    "                        [3,4], \n",
    "                        [5,6]])\n",
    "\n",
    "tensor_B = torch.tensor([[7,10],\n",
    "                         [8,11],\n",
    "                         [9,12]])\n",
    "\n",
    "# matrix multiplication 3 -> gives in error since shapes are not compatible for matrix multiplication\n",
    "# torch.mm(tensor_A, tensor_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f36395",
   "metadata": {},
   "source": [
    "To fix our tensor shape issues, we can manipulate the shape of one of our tensors using a **transpose**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "51f20db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27,  30,  33],\n",
       "        [ 61,  68,  75],\n",
       "        [ 95, 106, 117]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(tensor_A, tensor_B.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1834127",
   "metadata": {},
   "source": [
    "### Finding the min, max, mean, sum, etc (tensor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2b01d3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minimum\n",
    "x = torch.arange(0,100,10)\n",
    "print(x)\n",
    "x.min(), torch.min(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e6bea932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(90))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maximum \n",
    "torch.max(x), x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1d7836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9), tensor(9))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Argmax\n",
    "torch.argmax(x), x.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "92dbbf16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Argmin\n",
    "torch.argmin(x), x.argmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae7b404",
   "metadata": {},
   "source": [
    "### Reshaping, stacking, squeezing and unsqueezing tensors\n",
    "\n",
    "* Reshaping - Reshapes an input tensor to a defined shape\n",
    "* View - Return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
    "* Stacking - Combine multiple tensors on top of each other (vstack) or side by side (hstack)\n",
    "* Squeezing - Removes all `1` dimensions from a a tensor\n",
    "* Unsqueezing - Add a `1` dimension to a target tensor\n",
    "* Permute - Return a view of the input with dimensions permuted in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "86d4e390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]), torch.Size([10]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1,11)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c8064023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]]), torch.Size([1, 10]))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra deimension\n",
    "x_reshaped = x.reshape(1,10)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b508dd0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1],\n",
       "         [ 2],\n",
       "         [ 3],\n",
       "         [ 4],\n",
       "         [ 5],\n",
       "         [ 6],\n",
       "         [ 7],\n",
       "         [ 8],\n",
       "         [ 9],\n",
       "         [10]]),\n",
       " torch.Size([10, 1]))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the view, x remains in its original shape!\n",
    "z = x.view(10,1)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "76a39a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5],\n",
       "         [ 2],\n",
       "         [ 3],\n",
       "         [ 4],\n",
       "         [ 5],\n",
       "         [ 6],\n",
       "         [ 7],\n",
       "         [ 8],\n",
       "         [ 9],\n",
       "         [10]]),\n",
       " tensor([ 5,  2,  3,  4,  5,  6,  7,  8,  9, 10]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing z changes x (because a view of a tensor shares the same memory as the original input)\n",
    "z[0] = 5\n",
    "z,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "715337f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
       "        [ 5,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
       "        [ 5,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
       "        [ 5,  2,  3,  4,  5,  6,  7,  8,  9, 10]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "x_stacked = torch.stack([x,x,x,x])\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2552000e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  5,  5,  5],\n",
       "        [ 2,  2,  2,  2],\n",
       "        [ 3,  3,  3,  3],\n",
       "        [ 4,  4,  4,  4],\n",
       "        [ 5,  5,  5,  5],\n",
       "        [ 6,  6,  6,  6],\n",
       "        [ 7,  7,  7,  7],\n",
       "        [ 8,  8,  8,  8],\n",
       "        [ 9,  9,  9,  9],\n",
       "        [10, 10, 10, 10]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "x_stacked = torch.stack([x,x,x,x], dim=1)\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "34bffba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped Tensor: tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
      "Previous shape: torch.Size([1, 10])\n",
      "New tensor: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "New shape: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Squeeze - removes all the dimensions of size 1\n",
    "x = torch.arange(10)\n",
    "x_reshaped = x.reshape(1,10)\n",
    "print(f\"Reshaped Tensor: {x_reshaped}\")\n",
    "print(f\"Previous shape: {x_reshaped.shape}\")\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"New tensor: {x_squeezed}\")\n",
    "print(f\"New shape: {x_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1becb176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]),\n",
       " tensor([[0],\n",
       "         [1],\n",
       "         [2],\n",
       "         [3],\n",
       "         [4],\n",
       "         [5],\n",
       "         [6],\n",
       "         [7],\n",
       "         [8],\n",
       "         [9]]))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unsqueeze - Add a single dimension to a target tensor at a specific dimension\n",
    "x_unsqueezed0 = x_squeezed.unsqueeze(0)\n",
    "x_unsqueezed1 = x_squeezed.unsqueeze(1)\n",
    "x_unsqueezed0, x_unsqueezed1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0404ef34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# permute - rearrange the dimensions of a target tensor in a specified order\n",
    "x_original = torch.rand(size=(224,224,3))   # height, width, colour_channels\n",
    "\n",
    "# Permute the origina tensor to rearrange the axis order\n",
    "x_permuted = x_original.permute(2, 0, 1)    # colour_channels, height, width\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_permuted.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "423dc89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(728.)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing x_original also changes x_pernmuted\n",
    "x_original[0,0,0] = 728\n",
    "x_permuted[0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fbdcf2",
   "metadata": {},
   "source": [
    "### Indexing (selecting data from tensors)\n",
    "\n",
    "Indexing with PyTorch is similar to indexing with NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "542eae7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1,10).reshape(1,3,3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "76f2cdc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]),\n",
       " tensor([1, 2, 3]),\n",
       " tensor([1, 2, 3]),\n",
       " tensor(3))"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing our new tensor\n",
    "x[0], x[0][0], x[0,0], x[0,0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3caafc7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3]]), tensor([1, 2, 3]), tensor([[2, 5, 8]]))"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also use \":\" to select all of a target dimension\n",
    "x[:, 0], x[0,0,:], x[:,:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed90f44b",
   "metadata": {},
   "source": [
    "### PyTorch tensors and NumPy\n",
    "\n",
    "NumPy is a popular scientific Python numerical computing library. ANd because of this, PyTorch has functionality to interact with it.\n",
    "* Data in NumPy, want in PyTorch tensor - `torch.from_numpy(ndarray)`\n",
    "* PyTorch tensor to NumPy - ` torch.Tensor.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0f93de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy array to tensor - Be aware that the NumPy default datatype is float64 and torch reflects that datatype\n",
    "array = np.arange(1.,8.)\n",
    "tensor = torch.from_numpy(array)\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6794b267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the value of array, what will this do to tensor? - Nothing\n",
    "array = array + 1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "87b9b094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to NumPy array - Default datatype of PyTorch is reflected by NumPy\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "d90116f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 3., 3., 3., 3., 3., 3.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the tensor, what happens to numpy_tensor? - Again nothing\n",
    "tensor = tensor + 1\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3a9e7c",
   "metadata": {},
   "source": [
    "### Reproducibility (trying to take random out of random)\n",
    "\n",
    "In short, how a neural network learns is start with random numbers, perform tensor operations, update random numbers to try and make them better representations of the data, again, again, ...  \n",
    "To reduce the randomness in neural networks and PyTorch comes the concept of a **random seed**.  \n",
    "Essentially what the random seed does is \"flavour\" the randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "d10cf2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "# Create two random tensors\n",
    "random_tensor_A = torch.rand(3,4)\n",
    "random_tensor_B = torch.rand(3,4)\n",
    "print(random_tensor_A == random_tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27d2d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's make some random but reproducible tensors - manual_seed only works for one block of code!!!\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_C = torch.rand(3,4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_D = torch.rand(3,4)\n",
    "\n",
    "random_tensor_C == random_tensor_D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0426ed",
   "metadata": {},
   "source": [
    "## Running tensors and PyTorch objects on the GPUs (and making computations faster)\n",
    "\n",
    "GPUs = faster computation on numbers, thanks to CUDA + NVIDIA hardware + PyTorch working behind the scenes to make everything hunky dory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7253da6e",
   "metadata": {},
   "source": [
    "### 1. Getting a GPU\n",
    "\n",
    "1. Easiest - Use Google Colab for a free GPU (options to upgrade as well)\n",
    "2. Use your own GPU - takes a little bit of setup and requires the investmenet of purchasing a GPU, there's lots of options...\n",
    "3. Use cloud computing - GCP (Google), AWS (Amazon), Azure (Microsoft), ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f43c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following works in Colab after selecting GPU - gives information about GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e028f8f",
   "metadata": {},
   "source": [
    "### 2. Check for GPU access with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfbfbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU access with PyTorch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "27234299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# On mac we can use\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c35e788",
   "metadata": {},
   "source": [
    "## 3. Putting tensors (and models) on the GPU\n",
    "\n",
    "The reason we want our tensors/models on the GPU is because using a GPU results in faster computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650128db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor (default on the CPU)\n",
    "tensor = torch.tensor([1,2,3])\n",
    "tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "1121d7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move tensor to GPU (if available)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a142e0",
   "metadata": {},
   "source": [
    "### 4. Move tensors back to the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2250ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if tensor is on GPU, can't transform it to NumPy, since NumPy only works on cpu -> this gives an error\n",
    "#tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a407f62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To fix this issue, we can first set it to the CPU (both ways possible)\n",
    "tensor_on_cpu = tensor_on_gpu.to(\"cpu\").numpy()\n",
    "tensor_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "\n",
    "tensor_on_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f0b0bc",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "2dcef1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9625],\n",
       "        [1.0950],\n",
       "        [0.9967],\n",
       "        [1.8910],\n",
       "        [1.9205],\n",
       "        [1.0674],\n",
       "        [1.6949]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.Create a random tensor with shape (7, 7).\n",
    "t1 = torch.rand(7,7)\n",
    "\n",
    "# 3. Perform a matrix multiplication on the tensor from 2 with another random tensor with shape (1, 7) (hint: you may have to transpose the second tensor).\n",
    "t2 = torch.rand(1,7)\n",
    "t1 @ t2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "26775925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8823, 0.9150, 0.3829, 0.9593, 0.3904, 0.6009, 0.2566],\n",
       "        [0.7936, 0.9408, 0.1332, 0.9346, 0.5936, 0.8694, 0.5677],\n",
       "        [0.7411, 0.4294, 0.8854, 0.5739, 0.2666, 0.6274, 0.2696],\n",
       "        [0.4414, 0.2969, 0.8317, 0.1053, 0.2695, 0.3588, 0.1994],\n",
       "        [0.5472, 0.0062, 0.9516, 0.0753, 0.8860, 0.5832, 0.3376],\n",
       "        [0.8090, 0.5779, 0.9040, 0.5547, 0.3423, 0.6343, 0.3644],\n",
       "        [0.7104, 0.9464, 0.7890, 0.2814, 0.7886, 0.5895, 0.7539]])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Set the random seed to 0 and do exercises 2 & 3 over again.\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "t1 = torch.rand(7,7)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "ecc23595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Create two random tensors of shape (2, 3) and send them both to the GPU (you'll need access to a GPU for this). Set torch.manual_seed(1234) when creating the tensors (this doesn't have to be the GPU random seed).\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "t1 = torch.rand(2,3).to(device)\n",
    "t2 = torch.rand(2,3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "f74587c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Perform a matrix multiplication on the tensors you created in 6 (again, you may have to adjust the shapes of one of the tensors).\n",
    "t3 = t1 @ t2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "7fe95482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5617, device='mps:0'), tensor(0.3647, device='mps:0'))"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. Find the maximum and minimum values of the output of 7\n",
    "t3.max(), t3.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "15a51b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0, device='mps:0'), tensor(3, device='mps:0'))"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9. Find the maximum and minimum index values of the output of 7\n",
    "t3.argmin(), t3.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "507d630a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10. Make a random tensor with shape (1, 1, 1, 10) and then create a new tensor with all the 1 dimensions removed to be left with a tensor of shape (10). Set the seed to 7 when you create it and print out the first tensor and it's shape as well as the second tensor and it's shape.\n",
    "\n",
    "torch.manual_seed(7)\n",
    "random_tensor = torch.rand(1,1,1,10)\n",
    "print(random_tensor.shape)\n",
    "random_tensor_squeezed = random_tensor.squeeze()\n",
    "random_tensor_squeezed.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
